### 索引
- 作用：提升查询速度
- 为什么不用Hash：排序、分组、比较类型的查询，时间复杂度会退化为O(n)
- 为什么不用二叉树：高度比较高，而且每个节点只存储一个记录，多次I/O速度太慢
- 存储
  - InnoDB中`.ibd`文件存放索引和数据
  - MySQL的基本存储结构是**页**(每个页中有File Header、File tail、记录、**页目录**等数据)
  - 各个数据页可以组成一个**双向链表**
  - 每个数据页中的记录组成一个**单向链表**
  - 通过主键查找的时候可在页目录中用**二分法**快速定位到对应的槽，**遍历槽**即可快速找到记录
  - 非主键查找只能从最小记录开始依次遍历单链表中的每条记录
    - 遍历双向链表，找到所在的页
    - 遍历页中的单向链表
- B+树
  - B树(m分叉、每个节点存储j个数据)：利用了**局部性原理**
    - 内存比磁盘读写快很多
    - 磁盘有预读机制，即按页(一般4K)预读
    - 局部性原理：使用到一个数据，大概率使用到其附近的数据，磁盘预读能提升IO效率
    - B树将节点的大小设置为页大小能利用预读减少磁盘IO
  - B+树改进
    - 非叶子节点不再存储数据，只存储记录的主键(内存中存储更多记录的主键)
    - 叶子之间，增加了链表(获取所有节点、范围查找不再需要中序遍历)
- 聚集索引与非聚集索引
  - 聚集索引
    - 主键创建的索引
    - 叶子节点中存储表中的数据
    - 一个表只能有一个聚簇索引，而且必须包含主键
  - 非聚集索引(二级索引)
    - 非主键创建的索引
    - 叶子节点中存储主键和索引列
    - 使用非聚集索引查询，拿到叶子上的主键再去查找想要查找的数据(回表)
    - 多个非聚集索引会创建多个索引树
    - **覆盖索引**：要查的列和索引时对应的，不用回表
- **索引最左匹配**
  - 用于联合索引，一直向右匹配知道遇到范围查询(>、<、between、like)
- 多个=、in的顺序不用考虑，MySQL会自动优化
- 自适应Hash索引
  - 用户不感知
  - InnoDB注意到某个索引被频繁使用时，在内存中建立再建立一个Hash索引
- 使用经验
  - 联合索引最左前缀原则，建立的时候区分度最高的字段放到最左边
  - 不要在列上调用函数或者进行运算
  - 负向条件查询不能使用索引(`!=、<>、not in、not exists、not like`)
  - 使用覆盖索引
  - 避免强制类型转换
  - 范围列(`> < >= <= between`)可以用到索引，但是范围列之后的列无法使用到索引
  - 索引不允许为空，否则可能得到不符合预期的结果集
  - 更新频繁和数据区分度不高的字段不易建立索引
  - 避免在where中使用or来连接条件，会使索引失效(新版MySQL中能命中索引，但是还是比IN慢)
  - 前导模糊查询不能用索引，非前导可以
  - where中使用NULL判断会使索引失效

### 锁
- UPDATE INSERT DELETE语句，InnoDB自动给涉及的数据集加排他锁
- 锁的粒度
  - 表锁(MyISAM只支持表锁)
    - 分为表读锁和表写锁，读写、写写都会阻塞
    - 写锁优先于读锁
  - 行锁
    - **InnoDB的行锁基于索引**(只有通过索引条件索引数据时采用行级锁)
    - `共享锁--读锁--S锁` `SELECT * FROM XX WHERE ... LOCK IN SHARE MODE`：共享锁提高读读并发
    - `排他锁--写锁--X锁` `SELECT * FROM XX WHERE ... FOR UPDATE`
- 锁的策略
  - 乐观锁
    - 仅仅是一种策略，通过版本字段来CAS(update语句中匹配之前查到的version)
  - 悲观锁
    - 悲观锁会从数据库层面加锁
    - `select * from xxx for update`
- 间隙锁GAP
  - 用范围条件检索并请求锁的时候，InnoDB会给范围内的记录的索引加锁；同时对**范围内不存在**的记录也会加锁，即间隙锁
  - 间隙锁只会在Repeatable Read级别下使用
  - 目的
    - 防止幻读：幻读指某个事物读取某个范围内的记录时，另一个事务又在该范围插入了新的记录，之前的事务再次读取该范围的记录则会幻读
    - 满足恢复和复制的要求：一个事务未提交前，其他并发事务不能插入其锁定条件的任何记录，即不允许出现幻读
  - 意向锁
    - 并发插入同一个区间，使用插入意向锁不会相互阻塞
- 临建锁(Next-Key Locks)
  - 在Repeatable Read级别下彻底防止幻读
  - 记录锁与间隙锁的组合
  - 既锁记录本身，也锁住记录之前的区间(间隙锁范围为`(a, b)`，临建锁的范围为`(, ]`)
- 避免死锁
  - 以固定的顺序访问表和行
  - 大事务拆小
  - 同一个事务中，尽量一次锁定所有需要的资源
  - 降低隔离级别
  - 为表添加合理的索引
- MVCC(多版本并发控制)
  - 在Read Committed和Repeatable Read下工作
  - 能通过很小的开销实现非锁定读：写的时候复制一份数据(以版本区分)并操作直至提交，同时读任务可读取旧的数据
  - 原理：每个表有额外字段，与MVCC有关的为 DATA_TRX_ID DATA_ROLL_PTR(创建时间、删除时间)
    - DATA_TRX_ID：最近一次修改(add|update)本行记录的事务的标识符
    - DATA_ROLL_PTR：写入回滚段的undo log record(插入新数据的回滚段指针为null)
    - SELECT需要满足两个条件：早于(<=)当前事务版本的数据行;行的删除版本未定义或者大于当前事务版本号
    - INSERT：为每一行保存当前系统版本号作为行版本号
    - DELETE：为删除的每一行保存当前系统版本号作为行删除标识
    - UPDATE：插入一行新纪录，保存当前系统版本号作为行版本号，并保存当前系统版本号到原来的行作为行删除标识

### 优化
- `select count(*)`：MyISAM直接存储总行数，InnoDB按行扫描，有where条件时都一样
- 不建议用外检，而是通过应用程序来保证完整性
- 优化维度
  - 成本：硬件>系统配置>数据库表结构>SQL及索引
  - 效果：硬件<系统配置<数据库表结构<SQL及索引
- 优化工具
  - `show [SESSION | GLOBAL] variables` 查看数据库参数
  - `show [SESSION | GLOBAL] STATUS`  查看数据库状态
  - `show processlist`  查看当前所有连接session的状态
  - `explain` 查看执行计划
  - `show index`查看索引
  - `slow-log` 记录慢查询语句
  - `mysqldumpslow` 分析slowlog的工具
  - zabbix  监控主机、系统、数据库
  - pt-query-digest 分析慢日志
  - mysqlslap 分析慢日志
  - sysbench  压力测试
  - mysql profiling 统计数据库整体状态
  - Performance Schema mysql 性能状态统计的数据
  - workbench 管理、备份、监控、分析、优化
- 临时卡顿
  - show processlist
  - explain + show index
  - 判断索引问题或语句问题
  - `show status like '%lock%'`查询锁状态
  - kill SESSION_ID：杀掉有问题的session
- 周期性卡顿
  - 查看slowlog，分析出查询慢的语句
  - 分析stop sql，进行explain调试
  - 调整索引或者语句
- SQL优化
  - 尽量减小字段，减小主键，比如用整型存储IP
  - 避免使用NULL，NULL很难查询优化而且占用额外索引空间
  - 单表字段不要太多
  - 不用外键
  - 尽量不用UNIQUE
  - UNION ALL然后在代码中去重，而不是使用UNION在MySQL中去重
  - 避免多个范围条件比如`a>10 and b between 1 and 10`，无法同时使用a和b的索引
  - OR改成IN
  - 不用函数、存储过程和触发器
  - 连续数值用between而不是in
  - UPDATE时where也尽量走索引
  - 如果查询需要关联多张表，则只有**ORDER BY**子句引用的字段全部为**第一张表**时，才能使用索引做排序
  - limit
    - 当偏移量非常大的时候，代价很高，解决办法为尽可能的使用覆盖索引扫描，而不是查询所有的列。然后根据需要做一次关联查询再返回所有的列
    - 如果可以使用书签记录上次取数据的位置，那么下次就可以直接从该书签记录的位置开始扫描，这样就可以避免使用OFFSET
- 和缓存结合
  - 直写式：写入数据库后同时更新缓存，大多缓存框架比如Spring Cache都用这种，简单、同步号，但效率一般
  - 回写式：异步批量写入数据库，效率高但是可能导致数据不一致
